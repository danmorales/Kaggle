{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing fundamental libraries for data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading CSV file with Pandas Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the first five lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns id and Unnamed: 32 sicne they are unimportant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados.drop(['id','Unnamed: 32'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countplot to check the amount of each type of cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='diagnosis',data=dados)\n",
    "plt.xlabel('Diagnóstico')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Kind of diagnostic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the correlation among each of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dados.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(corr, annot=True, linewidths=.5, fmt= '.1f',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = dados.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of columns = {}\".format(len(colunas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots to check the distribution of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(6,5,figsize=(12,15))\n",
    "sns.boxplot(y=dados[colunas[1]],x=dados['diagnosis'],ax=ax[0][0])\n",
    "sns.boxplot(y=dados[colunas[2]],x=dados['diagnosis'],ax=ax[0][1])\n",
    "sns.boxplot(y=dados[colunas[3]],x=dados['diagnosis'],ax=ax[0][2])\n",
    "sns.boxplot(y=dados[colunas[4]],x=dados['diagnosis'],ax=ax[0][3])\n",
    "sns.boxplot(y=dados[colunas[5]],x=dados['diagnosis'],ax=ax[0][4])\n",
    "\n",
    "sns.boxplot(y=dados[colunas[6]],x=dados['diagnosis'],ax=ax[1][0])\n",
    "sns.boxplot(y=dados[colunas[7]],x=dados['diagnosis'],ax=ax[1][1])\n",
    "sns.boxplot(y=dados[colunas[8]],x=dados['diagnosis'],ax=ax[1][2])\n",
    "sns.boxplot(y=dados[colunas[9]],x=dados['diagnosis'],ax=ax[1][3])\n",
    "sns.boxplot(y=dados[colunas[10]],x=dados['diagnosis'],ax=ax[1][4])\n",
    "\n",
    "sns.boxplot(y=dados[colunas[11]],x=dados['diagnosis'],ax=ax[2][0])\n",
    "sns.boxplot(y=dados[colunas[12]],x=dados['diagnosis'],ax=ax[2][1])\n",
    "sns.boxplot(y=dados[colunas[13]],x=dados['diagnosis'],ax=ax[2][2])\n",
    "sns.boxplot(y=dados[colunas[14]],x=dados['diagnosis'],ax=ax[2][3])\n",
    "sns.boxplot(y=dados[colunas[15]],x=dados['diagnosis'],ax=ax[2][4])\n",
    "\n",
    "sns.boxplot(y=dados[colunas[16]],x=dados['diagnosis'],ax=ax[3][0])\n",
    "sns.boxplot(y=dados[colunas[17]],x=dados['diagnosis'],ax=ax[3][1])\n",
    "sns.boxplot(y=dados[colunas[18]],x=dados['diagnosis'],ax=ax[3][2])\n",
    "sns.boxplot(y=dados[colunas[19]],x=dados['diagnosis'],ax=ax[3][3])\n",
    "sns.boxplot(y=dados[colunas[20]],x=dados['diagnosis'],ax=ax[3][4])\n",
    "\n",
    "sns.boxplot(y=dados[colunas[21]],x=dados['diagnosis'],ax=ax[4][0])\n",
    "sns.boxplot(y=dados[colunas[22]],x=dados['diagnosis'],ax=ax[4][1])\n",
    "sns.boxplot(y=dados[colunas[23]],x=dados['diagnosis'],ax=ax[4][2])\n",
    "sns.boxplot(y=dados[colunas[24]],x=dados['diagnosis'],ax=ax[4][3])\n",
    "sns.boxplot(y=dados[colunas[25]],x=dados['diagnosis'],ax=ax[4][4])\n",
    "\n",
    "sns.boxplot(y=dados[colunas[26]],x=dados['diagnosis'],ax=ax[5][0])\n",
    "sns.boxplot(y=dados[colunas[27]],x=dados['diagnosis'],ax=ax[5][1])\n",
    "sns.boxplot(y=dados[colunas[28]],x=dados['diagnosis'],ax=ax[5][2])\n",
    "sns.boxplot(y=dados[colunas[29]],x=dados['diagnosis'],ax=ax[5][3])\n",
    "sns.boxplot(y=dados[colunas[30]],x=dados['diagnosis'],ax=ax[5][4])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing columns which values have a large range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_normalizar = colunas.drop('diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_norm = dados.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries to normalize the data and split into train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score,KFold,StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting categorical variable diagnosis to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enconder = LabelEncoder()\n",
    "dados_norm['diagnosis'] = enconder.fit_transform(dados_norm['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "for col in colunas_normalizar:\n",
    "    dados_norm[col] = scaler.fit_transform(dados_norm[col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados_norm.drop(['diagnosis'],axis=1)\n",
    "Y = dados_norm['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting sample into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_kfold = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for indice_treino, indice_teste in strat_kfold.split(X, Y):\n",
    "    #print(\"Treino:\", indice_treino, \"Teste:\", indice_teste)\n",
    "    X_treino, X_teste = X.iloc[indice_treino], X.iloc[indice_teste]\n",
    "    Y_treino, Y_teste = Y.iloc[indice_treino], Y.iloc[indice_teste]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries to compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,average_precision_score,classification_report,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV to find the best inputs of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo = []\n",
    "resultados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "precision =[]\n",
    "recall = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression\")\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000,10000,100000], \n",
    "                  'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(max_iter=2000), log_reg_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\n",
    "grid_log_reg.fit(X_treino, Y_treino)\n",
    "logreg = grid_log_reg.best_estimator_\n",
    "log_reg_score = cross_val_score(logreg, X_treino, Y_treino, cv=10,scoring='recall')\n",
    "print(\"Best Estimator\")\n",
    "print(logreg)\n",
    "print('Score Regressao Logistica Validacao Cruzada: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo.append(\"Logistic Regression\")\n",
    "resultados.append(log_reg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_treino,Y_treino)\n",
    "Y_pred_logreg = logreg.predict(X_teste)\n",
    "cm_logreg = confusion_matrix(Y_teste,Y_pred_logreg)\n",
    "acc_score_logreg = accuracy_score(Y_teste,Y_pred_logreg)\n",
    "f1_score_logreg = f1_score(Y_teste,Y_pred_logreg)\n",
    "precisao_logreg = average_precision_score(Y_teste,Y_pred_logreg)\n",
    "recall_logreg = recall_score(Y_teste,Y_pred_logreg)\n",
    "print('Acuracia Regressão Logistica ',round(acc_score_logreg*100,2).astype(str)+'%')\n",
    "print('Precião média Regressão Logistica ',round(precisao_logreg*100,2).astype(str)+'%')\n",
    "print('F1 Regressão Logistica ',round(f1_score_logreg*100,2).astype(str)+'%')\n",
    "print('Recall Regressão Logistica ',round(recall_logreg*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(acc_score_logreg)\n",
    "precision.append(precisao_logreg)\n",
    "recall.append(recall_logreg)\n",
    "f1.append(f1_score_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_logreg, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Regressão Logistica \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN\")\n",
    "knears_params = {\"n_neighbors\": list(range(5,40,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                'leaf_size' : list(range(3,40,1))}\n",
    "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\n",
    "grid_knears.fit(X_treino, Y_treino)\n",
    "knn = grid_knears.best_estimator_\n",
    "knears_score = cross_val_score(knn, X_treino, Y_treino, cv=10,scoring='recall')\n",
    "print(\"Best Estimator\")\n",
    "print(knn)\n",
    "print('Score KNN Validacao Cruzada: ', round(knears_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo.append(\"KNN\")\n",
    "resultados.append(knears_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_treino,Y_treino)\n",
    "Y_pred_knn = knn.predict(X_teste)\n",
    "cm_knn = confusion_matrix(Y_teste,Y_pred_knn)\n",
    "acc_score_knn = accuracy_score(Y_teste,Y_pred_knn)\n",
    "f1_score_knn = f1_score(Y_teste,Y_pred_knn)\n",
    "precisao_knn = average_precision_score(Y_teste,Y_pred_knn)\n",
    "recall_knn = recall_score(Y_teste,Y_pred_knn)\n",
    "print('Acuracia KNN ',round(acc_score_knn*100,2).astype(str)+'%')\n",
    "print('Precião média KNN ',round(precisao_knn*100,2).astype(str)+'%')\n",
    "print('F1 KNN ',round(f1_score_knn*100,2).astype(str)+'%')\n",
    "print('Recall KNN ',round(recall_knn*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(acc_score_knn)\n",
    "precision.append(precisao_knn)\n",
    "recall.append(recall_knn)\n",
    "f1.append(f1_score_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_knn, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"KNN \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ada Boost Classifier\")\n",
    "ada_params = {'n_estimators' : [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80], 'learning_rate' : [0.001,0.01,0.1,1.0], 'algorithm' : ['SAMME','SAMME.R']}\n",
    "grid_ada = GridSearchCV(AdaBoostClassifier(), ada_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\n",
    "grid_ada.fit(X_treino, Y_treino)\n",
    "ada = grid_ada.best_estimator_\n",
    "print(\"Best Estimator\")\n",
    "print(ada)\n",
    "ada_score = cross_val_score(ada, X_treino, Y_treino, cv=10,scoring='recall')\n",
    "print('Score AdaBoost Validacao Cruzada: ', round(ada_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo.append(\"AdaBoost\")\n",
    "resultados.append(ada_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.fit(X_treino,Y_treino)\n",
    "Y_pred_ada = ada.predict(X_teste)\n",
    "cm_ada = confusion_matrix(Y_teste,Y_pred_ada)\n",
    "acc_score_ada = accuracy_score(Y_teste,Y_pred_ada)\n",
    "f1_score_ada = f1_score(Y_teste,Y_pred_ada)\n",
    "precisao_ada = average_precision_score(Y_teste,Y_pred_ada)\n",
    "recall_ada = recall_score(Y_teste,Y_pred_ada)\n",
    "print('Acuracia ADA Boost ',round(acc_score_ada*100,2).astype(str)+'%')\n",
    "print('Precião média Ada Boost ',round(precisao_ada*100,2).astype(str)+'%')\n",
    "print('F1 Ada Boost ',round(f1_score_ada*100,2).astype(str)+'%')\n",
    "print('Recall Ada Boost ',round(recall_ada*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(acc_score_ada)\n",
    "precision.append(precisao_ada)\n",
    "recall.append(recall_ada)\n",
    "f1.append(f1_score_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_ada, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Ada Boost \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Classifier\")\n",
    "forest_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,20,1)), \n",
    "              \"min_samples_leaf\": list(range(3,20,1)), 'max_features' : ['auto','sqrt','log2']}\n",
    "forest = GridSearchCV(RandomForestClassifier(), forest_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\n",
    "forest.fit(X_treino, Y_treino)\n",
    "random_forest = forest.best_estimator_\n",
    "print(\"Best Estimator\")\n",
    "print(random_forest)\n",
    "forest_score = cross_val_score(random_forest, X_treino, Y_treino, cv=10,scoring='recall')\n",
    "print('Score RFC Validacao Cruzada: ', round(forest_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo.append(\"RFC\")\n",
    "resultados.append(forest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.fit(X_treino,Y_treino)\n",
    "Y_pred_rf = random_forest.predict(X_teste)\n",
    "cm_rf = confusion_matrix(Y_teste,Y_pred_rf)\n",
    "acc_score_rf = accuracy_score(Y_teste,Y_pred_rf)\n",
    "f1_score_rf = f1_score(Y_teste,Y_pred_rf)\n",
    "precisao_rf = average_precision_score(Y_teste,Y_pred_rf)\n",
    "recall_rf = recall_score(Y_teste,Y_pred_rf)\n",
    "print('Acuracia Random Forest ',round(acc_score_rf*100,2).astype(str)+'%')\n",
    "print('Precião média Random Forest ',round(precisao_rf*100,2).astype(str)+'%')\n",
    "print('F1 Random Forest ',round(f1_score_rf*100,2).astype(str)+'%')\n",
    "print('Recall Random Forest ',round(recall_rf*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(acc_score_rf)\n",
    "precision.append(precisao_rf)\n",
    "recall.append(recall_rf)\n",
    "f1.append(f1_score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_rf, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Random Forest \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Boost Classifier\")\n",
    "grad_params = {'n_estimators' : [30,35,40,45,50,55,60,65,70], 'learning_rate' : [0.001,0.01,0.1,1.0], 'loss' : ['deviance','exponential'],\n",
    "              'max_depth' : [3,4,5,6,7], 'max_features' : ['auto','sqrt','log2'], 'min_samples_leaf' : [2,3,4,5,6]}\n",
    "grad = GridSearchCV(GradientBoostingClassifier(), grad_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\n",
    "grad.fit(X_treino, Y_treino)\n",
    "grad_boost = grad.best_estimator_\n",
    "print(\"Best Estimator\")\n",
    "print(grad_boost)\n",
    "grad_score = cross_val_score(grad_boost, X_treino, Y_treino, cv=10,scoring='recall')\n",
    "print('Score GradBoost Validacao Cruzada: ', round(grad_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo.append(\"GradBoost\")\n",
    "resultados.append(grad_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost.fit(X_treino,Y_treino)\n",
    "Y_pred_gb = grad_boost.predict(X_teste)\n",
    "cm_gb = confusion_matrix(Y_teste,Y_pred_gb)\n",
    "acc_score_gb = accuracy_score(Y_teste,Y_pred_gb)\n",
    "f1_score_gb = f1_score(Y_teste,Y_pred_gb)\n",
    "precisao_gb = average_precision_score(Y_teste,Y_pred_gb)\n",
    "recall_gb = recall_score(Y_teste,Y_pred_gb)\n",
    "print('Acuracia Gradient Boosting ',round(acc_score_gb*100,2).astype(str)+'%')\n",
    "print('Precião média Gradient Boosting  ',round(precisao_gb*100,2).astype(str)+'%')\n",
    "print('F1 Gradient Boosting  ',round(f1_score_gb*100,2).astype(str)+'%')\n",
    "print('Recall Gradient Boosting  ',round(recall_gb*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(acc_score_gb)\n",
    "precision.append(precisao_gb)\n",
    "recall.append(recall_gb)\n",
    "f1.append(f1_score_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_gb, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Gradient Boosting  \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,7))\n",
    "plt.boxplot(resultados)\n",
    "ax.set_xticklabels(nome_modelo)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_treino.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Dense(32, input_shape=(n_inputs, ), activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "modelo.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "modelo.add(Dropout(0.5))\n",
    "modelo.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "modelo.add(Dense(32, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "modelo.add(Dropout(0.5))\n",
    "modelo.add(Dense(2, activation='softmax', kernel_initializer='glorot_uniform',bias_initializer='zeros'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, mode='auto', min_delta=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [reduce_lr,es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(Adam(lr=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "modelo.fit(X_treino, Y_treino, batch_size=20, epochs=200, verbose=2, validation_data=(X_teste,Y_teste),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_keras = modelo.predict_classes(X_teste, batch_size=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_keras = confusion_matrix(Y_teste,Y_pred_keras)\n",
    "acc_score_keras = accuracy_score(Y_teste,Y_pred_keras)\n",
    "f1_score_keras = f1_score(Y_teste,Y_pred_keras)\n",
    "precisao_keras = average_precision_score(Y_teste,Y_pred_keras)\n",
    "recall_keras = recall_score(Y_teste,Y_pred_keras)\n",
    "print('Acuracia Keras ',round(acc_score_keras*100,2).astype(str)+'%')\n",
    "print('Precião média Keras  ',round(precisao_keras*100,2).astype(str)+'%')\n",
    "print('F1 Gradient Boosting  ',round(f1_score_keras*100,2).astype(str)+'%')\n",
    "print('Recall Keras  ',round(recall_keras*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo.append(\"Keras\")\n",
    "accuracy.append(acc_score_keras)\n",
    "precision.append(precisao_keras)\n",
    "recall.append(recall_keras)\n",
    "f1.append(f1_score_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_keras, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Keras  \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the K best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['diagnosis'] = enconder.fit_transform(dados['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados.drop(['diagnosis'],axis=1)\n",
    "Y = dados['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_features(X,Y,n):\n",
    "    X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "    best_features = SelectKBest(chi2, k=n).fit(X_treino, Y_treino)\n",
    "    X_treino = best_features.transform(X_treino)\n",
    "    X_teste = best_features.transform(X_teste)\n",
    "    acc,precision,recall,f1 = best_logred_model(X_treino,Y_treino,X_teste,Y_teste)\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_logred_model(X_treino_best,Y_treino_best,X_teste,Y_teste):\n",
    "    #print(\"Logistic Regression\")\n",
    "    log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1e3,1e4,1e5,1e6], \n",
    "                  'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "    grid_log_reg = GridSearchCV(LogisticRegression(max_iter=2000), log_reg_params,n_jobs=8,cv=10)\n",
    "    grid_log_reg.fit(X_treino_best, Y_treino_best)\n",
    "    logreg = grid_log_reg.best_estimator_\n",
    "    logreg.fit(X_treino_best,Y_treino_best)\n",
    "    Y_pred_Kbest = logreg.predict(X_teste)\n",
    "    acc_kest = accuracy_score(Y_teste,Y_pred_Kbest)\n",
    "    f1_kbest = f1_score(Y_teste,Y_pred_Kbest)\n",
    "    precisao_kbest = average_precision_score(Y_teste,Y_pred_Kbest)\n",
    "    recall_kbest = recall_score(Y_teste,Y_pred_Kbest)\n",
    "    return acc_kest,precisao_kbest,recall_kbest,f1_kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_findbest = []\n",
    "rec_findbest = []\n",
    "prec_findbest = []\n",
    "f1s_findbest= []\n",
    "n_idex = []\n",
    "\n",
    "for n in range(5,len(dados.columns)-1):\n",
    "    acuracia,precisao,recallx,f1x = find_best_features(X,Y,n)\n",
    "    acc_findbest.append(acuracia)\n",
    "    rec_findbest.append(recallx)\n",
    "    prec_findbest.append(precisao)\n",
    "    f1s_findbest.append(f1x)\n",
    "    n_idex.append(n)\n",
    "    print(\"N = \",n,\"Acc = \",acuracia, \"Prec = \",precisao, \"Rec = \",recallx, \"F1 = \",f1x)\n",
    "    \n",
    "dic_kbest = {\"N\" : n_idex, \"Acuracia\" : acc, \"Recall\" : rec, \"Precision\" : prec, \"F1\" : f1s}\n",
    "\n",
    "dataframe_kbest = pd.DataFrame(dic_kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_kbest = dataframe_kbest.sort_values(by=['Acuracia','Recall','F1','Precision'],ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = int(dataframe_kbest.iloc[0]['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino_best, X_teste_best, Y_treino_best, Y_teste_best = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_kbest = SelectKBest(chi2, k=int(best_n)).fit(X_treino_best, Y_treino_best)\n",
    "X_treino_best = modelo_kbest.transform(X_treino_best)#.values\n",
    "X_teste_best = modelo_kbest.transform(X_teste_best)#.values\n",
    "Y_treino_best = Y_treino_best.values\n",
    "Y_teste_best = Y_teste_best.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kbest = []\n",
    "precison_kbest =[]\n",
    "recall_kbest = []\n",
    "f1_kbest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1e3,1e4], \n",
    "                  'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(max_iter=2000), log_reg_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='f1')\n",
    "grid_log_reg.fit(X_treino_best, Y_treino_best)\n",
    "logreg = grid_log_reg.best_estimator_\n",
    "logreg.fit(X_treino_best,Y_treino_best)\n",
    "Y_pred_best = logreg.predict(X_teste_best)\n",
    "cm_best = confusion_matrix(Y_teste_best,Y_pred_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_best, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Regressão logistica  \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_logreg_best = accuracy_score(Y_teste_best,Y_pred_best)\n",
    "f1_score_logreg_best = f1_score(Y_teste_best,Y_pred_best)\n",
    "precisao_logreg_best = average_precision_score(Y_teste_best,Y_pred_best)\n",
    "recall_logreg_best = recall_score(Y_teste_best,Y_pred_best)\n",
    "print('Acuracia Regressão Logistica ',round(acc_score_logreg_best*100,2).astype(str)+'%')\n",
    "print('Precião média Regressão Logistica ',round(precisao_logreg_best*100,2).astype(str)+'%')\n",
    "print('F1 Regressão Logistica ',round(f1_score_logreg_best*100,2).astype(str)+'%')\n",
    "print('Recall Regressão Logistica ',round(recall_logreg_best*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kbest.append(acc_score_logreg_best)\n",
    "precison_kbest.append(precisao_logreg_best)\n",
    "recall_kbest.append(recall_logreg_best)\n",
    "f1_kbest.append(f1_score_logreg_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knears_params = {\"n_neighbors\": list(range(5,40,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                'leaf_size' : list(range(2,40,1))}\n",
    "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\n",
    "grid_knears.fit(X_treino_best, Y_treino_best)\n",
    "knn = grid_knears.best_estimator_\n",
    "knn.fit(X_treino_best,Y_treino_best)\n",
    "Y_pred_best_knn = knn.predict(X_teste_best)\n",
    "cm_best_knn = confusion_matrix(Y_teste_best,Y_pred_best_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_best_knn, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"KNN  \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_knn = accuracy_score(Y_teste_best,Y_pred_best_knn)\n",
    "f1_score_knn = f1_score(Y_teste_best,Y_pred_best_knn)\n",
    "precisao_knn = average_precision_score(Y_teste_best,Y_pred_best_knn)\n",
    "recall_knn = recall_score(Y_teste_best,Y_pred_best_knn)\n",
    "print('Acuracia KNN ',round(acc_score_knn*100,2).astype(str)+'%')\n",
    "print('Precião média KNN ',round(precisao_knn*100,2).astype(str)+'%')\n",
    "print('F1 KNN ',round(f1_score_knn*100,2).astype(str)+'%')\n",
    "print('Recall KNN ',round(recall_knn*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kbest.append(acc_score_knn)\n",
    "precison_kbest.append(precisao_knn)\n",
    "recall_kbest.append(recall_knn)\n",
    "f1_kbest.append(f1_score_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_params = {'n_estimators' : list(range(5,81)), 'learning_rate' : [0.001,0.01,0.1,1.0], 'algorithm' : ['SAMME','SAMME.R']}\n",
    "grid_ada = GridSearchCV(AdaBoostClassifier(), ada_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='f1')\n",
    "grid_ada.fit(X_treino_best, Y_treino_best)\n",
    "ada = grid_ada.best_estimator_\n",
    "ada.fit(X_treino_best,Y_treino_best)\n",
    "Y_pred_best_ada = ada.predict(X_teste_best)\n",
    "cm_best_ada = confusion_matrix(Y_teste_best,Y_pred_best_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_best_ada, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Ada Boost  \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_ada_best = accuracy_score(Y_teste_best,Y_pred_best_ada)\n",
    "f1_score_ada_best = f1_score(Y_teste_best,Y_pred_best_ada)\n",
    "precisao_ada_best = average_precision_score(Y_teste_best,Y_pred_best_ada)\n",
    "recall_ada_best = recall_score(Y_teste_best,Y_pred_best_ada)\n",
    "print('Acuracia Ada Boost ',round(acc_score_ada_best*100,2).astype(str)+'%')\n",
    "print('Precião média Ada Boost ',round(precisao_ada_best*100,2).astype(str)+'%')\n",
    "print('F1 Ada Boost ',round(f1_score_ada_best*100,2).astype(str)+'%')\n",
    "print('Recall Ada Boost ',round(recall_ada_best*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kbest.append(acc_score_ada_best)\n",
    "precison_kbest.append(precisao_ada_best)\n",
    "recall_kbest.append(recall_ada_best)\n",
    "f1_kbest.append(f1_score_ada_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,20,1)), \n",
    "              \"min_samples_leaf\": list(range(3,20,1)), 'max_features' : ['auto','sqrt','log2']}\n",
    "forest = GridSearchCV(RandomForestClassifier(), forest_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\n",
    "forest.fit(X_treino_best, Y_treino_best)\n",
    "random_forest = forest.best_estimator_\n",
    "random_forest.fit(X_treino_best,Y_treino_best)\n",
    "Y_pred_best_rf = random_forest.predict(X_teste_best)\n",
    "cm_best_rf = confusion_matrix(Y_teste_best,Y_pred_best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_best_rf, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Random Forest  \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_rf_best = accuracy_score(Y_teste_best,Y_pred_best_rf)\n",
    "f1_score_rf_best = f1_score(Y_teste_best,Y_pred_best_rf)\n",
    "precisao_rf_best = average_precision_score(Y_teste_best,Y_pred_best_rf)\n",
    "recall_rf_best = recall_score(Y_teste_best,Y_pred_best_rf)\n",
    "print('Acuracia Random Forest ',round(acc_score_rf_best*100,2).astype(str)+'%')\n",
    "print('Precião média Random Forest ',round(precisao_rf_best*100,2).astype(str)+'%')\n",
    "print('F1 Random Forest ',round(f1_score_rf_best*100,2).astype(str)+'%')\n",
    "print('Recall Random Forest ',round(recall_rf_best*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kbest.append(acc_score_rf_best)\n",
    "precison_kbest.append(precisao_rf_best)\n",
    "recall_kbest.append(recall_rf_best)\n",
    "f1_kbest.append(f1_score_rf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_params = {'n_estimators' : [30,35,40,45,50,55,60,65,70], 'learning_rate' : [0.001,0.01,0.1,1.0], 'loss' : ['deviance','exponential'],\n",
    "              'max_depth' : [3,4,5,6,7], 'max_features' : ['auto','sqrt','log2'], 'min_samples_leaf' : [2,3,4,5,6]}\n",
    "grad = GridSearchCV(GradientBoostingClassifier(), grad_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\n",
    "grad.fit(X_treino_best, Y_treino_best)\n",
    "grad_boost = grad.best_estimator_\n",
    "grad_boost.fit(X_treino_best,Y_treino_best)\n",
    "Y_pred_best_grad = grad_boost.predict(X_teste_best)\n",
    "cm_best_grad = confusion_matrix(Y_teste_best,Y_pred_best_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_best_grad, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Gradient Boosting  \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_grad_best = accuracy_score(Y_teste_best,Y_pred_best_grad)\n",
    "f1_score_grad_best = f1_score(Y_teste_best,Y_pred_best_grad)\n",
    "precisao_grad_best = average_precision_score(Y_teste_best,Y_pred_best_grad)\n",
    "recall_grad_best = recall_score(Y_teste_best,Y_pred_best_grad)\n",
    "print('Acuracia Random Forest ',round(acc_score_grad_best*100,2).astype(str)+'%')\n",
    "print('Precião média Random Forest ',round(precisao_grad_best*100,2).astype(str)+'%')\n",
    "print('F1 Random Forest ',round(f1_score_grad_best*100,2).astype(str)+'%')\n",
    "print('Recall Random Forest ',round(recall_grad_best*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kbest.append(acc_score_grad_best)\n",
    "precison_kbest.append(precisao_grad_best)\n",
    "recall_kbest.append(recall_grad_best)\n",
    "f1_kbest.append(f1_score_grad_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_treino_best.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2 = Sequential()\n",
    "modelo2.add(Dense(32, input_shape=(n_inputs, ), activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "modelo2.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "modelo2.add(Dropout(0.5))\n",
    "modelo2.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "modelo2.add(Dense(32, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "modelo2.add(Dropout(0.5))\n",
    "modelo2.add(Dense(2, activation='softmax', kernel_initializer='glorot_uniform',bias_initializer='zeros'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2.compile(Adam(lr=0.01), loss='sparse_categorical_crossentropy', metrics=['top_k_categorical_accuracy'])\n",
    "modelo2.fit(X_treino_best, Y_treino_best, batch_size=20, epochs=200, verbose=2, validation_data=(X_teste_best,Y_teste_best),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_keras = modelo2.predict_classes(X_teste_best, batch_size=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_keras = confusion_matrix(Y_teste_best,Y_pred_keras)\n",
    "acc_score_keras = accuracy_score(Y_teste_best,Y_pred_keras)\n",
    "f1_score_keras = f1_score(Y_teste_best,Y_pred_keras)\n",
    "precisao_keras = average_precision_score(Y_teste_best,Y_pred_keras)\n",
    "recall_keras = recall_score(Y_teste_best,Y_pred_keras)\n",
    "print('Acuracia Keras ',round(acc_score_keras*100,2).astype(str)+'%')\n",
    "print('Precião média Keras  ',round(precisao_keras*100,2).astype(str)+'%')\n",
    "print('F1 Gradient Boosting  ',round(f1_score_keras*100,2).astype(str)+'%')\n",
    "print('Recall Keras  ',round(recall_keras*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kbest.append(acc_score_keras)\n",
    "precison_kbest.append(precisao_keras)\n",
    "recall_kbest.append(recall_keras)\n",
    "f1_kbest.append(f1_score_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_metrics = {'Model' : nome_modelo, 'Accuracy' : accuracy, 'Precision' : precision, 'Recall' : recall, 'F1' : f1, \n",
    "              'Accuracy_Kbest' : acc_kbest, 'Precision_Kbest' : precison_kbest, 'Recall_Kbest' : recall_kbest,\n",
    "              'F1_Kbest' : f1_kbest}\n",
    "\n",
    "dataframe = pd.DataFrame(dic_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
