{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.transform import rescale, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer,MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,average_precision_score,classification_report,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_accuracy,binary_accuracy,sparse_categorical_accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, ReLU, BatchNormalization, GlobalAveragePooling2D,LeakyReLU\n",
    "from keras.optimizers import RMSprop, SGD, Adadelta, Adam, Adagrad, Adamax, Nadam\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path,size1,size2):\n",
    "\n",
    "    im = io.imread(image_path)\n",
    "    im = resize(im, (size1, size2,3), anti_aliasing=True)\n",
    "    img = im.astype(float)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagens(size1,size2):\n",
    "\n",
    "    todas_figuras = []\n",
    "    classe=[]\n",
    "    Path = 'Images/'\n",
    "    \n",
    "    figuras=os.listdir(Path)\n",
    "    for tipo in figuras:\n",
    "        figura=os.listdir(Path+tipo)\n",
    "        for figuras in figura:\n",
    "            todas_figuras.append(preprocess_image(Path+tipo+'/'+figuras,size1,size2))\n",
    "            classe.append(tipo)\n",
    "            \n",
    "    tamanho_pinturas = len(todas_figuras)\n",
    "    tamanho_nomes = len(classe)\n",
    "    print(\"Tamanho do arranjo figuras = \",tamanho_pinturas)\n",
    "    print(\"Tamanho do arranjo nomes = \",tamanho_nomes)\n",
    "    \n",
    "    return np.array(todas_figuras),np.array(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape, nclasses):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", input_shape=input_shape,name='convo1_bloco1'))\n",
    "    model.add(BatchNormalization(name='batch_normalization1_bloco1'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\",name='conv2_bloco1'))\n",
    "    model.add(BatchNormalization(name='batch_normalization2_bloco1'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2),padding='valid',name='maxpool_bloco1'))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding=\"same\",name='convo1_bloco2'))\n",
    "    model.add(BatchNormalization(name='batch_normalization1_bloco2'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding=\"same\",name='convo2_bloco2'))\n",
    "    model.add(BatchNormalization(name='batch_normalization2_bloco2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2),padding='valid',name='maxpool_bloco2'))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding=\"same\",name='convo1_bloco3'))\n",
    "    model.add(BatchNormalization(name='batch_normalization1_bloco3'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding=\"same\",name='convo2_bloco3'))\n",
    "    model.add(BatchNormalization(name='batch_normalization2_bloco3'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding=\"same\",name='convo3_bloco3'))\n",
    "    model.add(BatchNormalization(name='batch_normalization3_bloco3'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding=\"same\",name='convo4_bloco3'))\n",
    "    model.add(BatchNormalization(name='batch_normalization4_bloco3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2),padding='valid',name='maxpool_bloco3'))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo1_bloco4'))\n",
    "    model.add(BatchNormalization(name='batch_normalization1_bloco4'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo2_bloco4'))\n",
    "    model.add(BatchNormalization(name='batch_normalization2_bloco4'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo3_bloco4'))\n",
    "    model.add(BatchNormalization(name='batch_normalization3_bloco4'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo4_bloco4'))\n",
    "    model.add(BatchNormalization(name='batch_normalization4_bloco4'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2),padding='valid',name='maxpool_bloco4'))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo1_bloco5'))\n",
    "    model.add(BatchNormalization(name='batch_normalization1_bloco5'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo2_bloco5'))\n",
    "    model.add(BatchNormalization(name='batch_normalization2_bloco5'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo3_bloco5'))\n",
    "    model.add(BatchNormalization(name='batch_normalization3_bloco5'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo4_bloco5'))\n",
    "    model.add(BatchNormalization(name='batch_normalization4_bloco5'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2),padding='valid',name='maxpool_bloco5'))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo1_bloco6'))\n",
    "    model.add(BatchNormalization(name='batch_normalization1_bloco6'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo2_bloco6'))\n",
    "    model.add(BatchNormalization(name='batch_normalization2_bloco6'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo3_bloco6'))\n",
    "    model.add(BatchNormalization(name='batch_normalization3_bloco6'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding=\"same\",name='convo4_bloco6'))\n",
    "    model.add(BatchNormalization(name='batch_normalization4_bloco6'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2),padding='valid',name='maxpool_bloco6'))\n",
    "    \n",
    "    model.add(Flatten(name='Flatten'))\n",
    "\n",
    "    model.add(Dense(2048, activation='relu',name='Dense_1'))\n",
    "    model.add(BatchNormalization(name='batch_normalization_Dense1'))\n",
    "    \n",
    "    model.add(Dense(2048, activation='relu',name='Dense_2'))\n",
    "    model.add(BatchNormalization(name='batch_normalization_Dense2'))\n",
    "    \n",
    "    if(nclasses>2):\n",
    "        model.add(Dense(nclasses , activation='softmax',name='Output_Dense'))\n",
    "    else:\n",
    "        model.add(Dense(1 , activation='sigmoid',name='Output_Dense'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size1 = 128\n",
    "size2 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Carregando imagens\")\n",
    "imagens, classes = load_imagens(size1,size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = classes.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques, ids = np.unique(classes, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder =  LabelEncoder()\n",
    "y_classes = encoder.fit_transform(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(imagens, y_classes, test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = createModel(imagens[0].shape, nclasses=n_classes)\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(opt == 'SGD'):\n",
    "    print(\"Optimizer = SGD\")\n",
    "    optimizer = SGD(lr=0.1, decay=1e-2/epochs, momentum=0.95, nesterov=True)\n",
    "elif (opt == 'RMS'):\n",
    "    print(\"Optimizer = RMS\")\n",
    "    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-05, decay=0.0)\n",
    "elif (opt == 'Adadelta'):\n",
    "    print(\"Optimizer = Adadelta\")\n",
    "    optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "elif (opt == 'Adam'):\n",
    "    print(\"Optimizer = Adam\")\n",
    "    optimizer = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-2, decay=1e-5/epochs, amsgrad=True)\n",
    "elif (opt == 'Adagrad'):\n",
    "    print(\"Optimizer = Adagrad\")\n",
    "    optimizer = Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "elif (opt == 'Adamax'):\n",
    "    print(\"Optimizer = Adamax\")\n",
    "    optimizer = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-5/epochs)\n",
    "elif (opt == 'NAdam'):\n",
    "    print(\"Optimizer = NAdam\")\n",
    "    optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, mode='auto', epsilon=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1='categorical_crossentropy'\n",
    "loss2='sparse_categorical_crossentropy'\n",
    "loss3 = \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer=optimizer, loss=loss3, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modelo.fit(X_train, y_train, batch_size=batch_size,epochs=epochs,validation_data=(X_test, y_test), callbacks=[learning_rate_reduction,checkpoint,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_keras = modelo.predict_classes(X_test, batch_size=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_keras = confusion_matrix(y_test,Y_pred_keras)\n",
    "acc_score_keras = accuracy_score(y_test,Y_pred_keras)\n",
    "f1_score_keras = f1_score(y_test,Y_pred_keras)\n",
    "precisao_keras = average_precision_score(y_test,Y_pred_keras)\n",
    "recall_keras = recall_score(y_test,Y_pred_keras)\n",
    "print('Acuracia Keras ',round(acc_score_keras*100,2).astype(str)+'%')\n",
    "print('Precião média Keras  ',round(precisao_keras*100,2).astype(str)+'%')\n",
    "print('F1 Gradient Boosting  ',round(f1_score_keras*100,2).astype(str)+'%')\n",
    "print('Recall Keras  ',round(recall_keras*100,2).astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(cm_keras, ax=ax, annot=True, cmap=plt.cm.copper)\n",
    "ax.set_title(\"Keras  \\n Matriz de Confusão\", fontsize=14)\n",
    "ax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\n",
    "ax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
